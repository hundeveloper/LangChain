{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6af41a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ OpenAI API ì •ìƒ ì¸ì¦ ì™„ë£Œ âœ…\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=openai.api_key)\n",
    "\n",
    "try:\n",
    "    models = client.models.list()\n",
    "    print(\"ğŸ”‘ OpenAI API ì •ìƒ ì¸ì¦ ì™„ë£Œ âœ…\")\n",
    "except Exception as e:\n",
    "    print(\"âŒ ì¸ì¦ ì‹¤íŒ¨:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d11e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: c:\\Users\\hun\\Desktop\\llm_example\n",
      "ğŸ“„ data í´ë” ë‚´ íŒŒì¼ ëª©ë¡: ['ai-terminology.txt', 'ai_technologies.csv', 'finance-terminology.txt', 'taxinfo.txt', 'titanic.csv', 'tutorial-korean.pdf', 'ìŒì‹_recommendations.csv', 'ì½˜í…ì¸ ë¶„ìŸí•´ê²°_ì‚¬ë¡€.pdf']\n",
      "âœ… 109ê°œ í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# 0ë‹¨ê³„: PDF ë¬¸ì„œ ë¡œë”©\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = \"./data/ì½˜í…ì¸ ë¶„ìŸí•´ê²°_ì‚¬ë¡€.pdf\"\n",
    "\n",
    "print(\"ğŸ“ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬:\", os.getcwd())\n",
    "print(\"ğŸ“„ data í´ë” ë‚´ íŒŒì¼ ëª©ë¡:\", os.listdir(\"./data\"))\n",
    "\n",
    "if os.path.exists(pdf_path):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    print(f\"âœ… {len(documents)}ê°œ í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"âŒ PDF íŒŒì¼ ê²½ë¡œê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f1b30c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§© ë¶„í• ëœ ì²­í¬ ìˆ˜: 104\n"
     ]
    }
   ],
   "source": [
    "# 1ë‹¨ê³„: ë¬¸ì„œ ë¶„í• \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=300,\n",
    "    separators=[\n",
    "        \"\\nã€ì‚¬ê±´ê°œìš”ã€‘\", \"\\nã€ìŸì ì‚¬í•­ã€‘\", \"\\nã€ì²˜ë¦¬ê²½ìœ„ã€‘\", \"\\nã€ì²˜ë¦¬ê²°ê³¼ã€‘\",\n",
    "        \"\\nâ– \", \"\\n\\n\", \"\\n\", \".\", \" \", \"\"\n",
    "    ]\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"ğŸ§© ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "749f1262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ë‹¨ê³„: ì„ë² ë”© ì„¤ì •\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    dimensions=1536\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebbfc0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 3ë‹¨ê³„: ë²¡í„°ìŠ¤í† ì–´ ë° ê²€ìƒ‰ê¸° ì„¤ì •\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m vectorstore = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m retriever = vectorstore.as_retriever(\n\u001b[32m      7\u001b[39m     search_type=\u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     search_kwargs={\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m5\u001b[39m}\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[33;03m\"\"\"RateLimitError: Error code: 429\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03m\"You exceeded your current quota\" â†’ ì‚¬ìš© ê°€ëŠ¥í•œ OpenAI API **ì¿¼í„°(ìš”ê¸ˆì œ í•œë„)**ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\chatbot-DD67osgJ-py3.12\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:848\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    846\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\chatbot-DD67osgJ-py3.12\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1043\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> FAISS:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     embeddings = \u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__from(\n\u001b[32m   1045\u001b[39m         texts,\n\u001b[32m   1046\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1050\u001b[39m         **kwargs,\n\u001b[32m   1051\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\chatbot-DD67osgJ-py3.12\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:590\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[32m    588\u001b[39m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[32m    589\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\chatbot-DD67osgJ-py3.12\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:478\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m batched_embeddings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_kwargs\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    482\u001b[39m         response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\chatbot-DD67osgJ-py3.12\\Lib\\site-packages\\openai\\resources\\embeddings.py:129\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    123\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    124\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    125\u001b[39m             ).tolist()\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\chatbot-DD67osgJ-py3.12\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\chatbot-DD67osgJ-py3.12\\Lib\\site-packages\\openai\\_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# 3ë‹¨ê³„: ë²¡í„°ìŠ¤í† ì–´ ë° ê²€ìƒ‰ê¸° ì„¤ì •\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunks[:10], embeddings)\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "\"\"\"RateLimitError: Error code: 429\n",
    "\"You exceeded your current quota\" â†’ ì‚¬ìš© ê°€ëŠ¥í•œ OpenAI API **ì¿¼í„°(ìš”ê¸ˆì œ í•œë„)**ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.\"\n",
    "ì´ ì´ˆê³¼ë¡œ ì¸í•´ ë¬¸ì œë¥¼ í’‰ë‹ˆë‹¤ ã… ã… \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3fd27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ë‹¨ê³„: LLM ì„¤ì •\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec5cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "ë‹¹ì‹ ì€ ì½˜í…ì¸  ë¶„ì•¼ ì „ë¬¸ ë²•ë¥  ìë¬¸ì‚¬ì…ë‹ˆë‹¤. \n",
    "ì•„ë˜ ë¶„ìŸì¡°ì • ì‚¬ë¡€ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë²•ë¥  ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ê´€ë ¨ ë¶„ìŸì‚¬ë¡€:\n",
    "{context}\n",
    "\n",
    "ìƒë‹´ ë‚´ìš©: {question}\n",
    "\n",
    "ë‹µë³€ ê°€ì´ë“œë¼ì¸:\n",
    "1. ì œì‹œëœ ì‚¬ë¡€ë“¤ì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”\n",
    "2. ê´€ë ¨ ë²•ë ¹ì´ë‚˜ ì¡°í•­ì´ ìˆë‹¤ë©´ ëª…ì‹œí•˜ì„¸ìš”\n",
    "3. ë¹„ìŠ·í•œ ì‚¬ë¡€ì˜ ì²˜ë¦¬ê²½ìœ„ì™€ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”\n",
    "4. ì‹¤ë¬´ì  í•´ê²°ë°©ì•ˆì„ ë‹¨ê³„ë³„ë¡œ ì œì‹œí•˜ì„¸ìš”\n",
    "5. ì‚¬ë¡€ì— ì—†ëŠ” ë‚´ìš©ì€ \"ì œì‹œëœ ì‚¬ë¡€ì§‘ì—ì„œëŠ” í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”\n",
    "\n",
    "ì „ë¬¸ ë²•ë¥  ì¡°ì–¸:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc1e31d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 6ë‹¨ê³„: QA ì²´ì¸ ìƒì„±\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA\n\u001b[32m      4\u001b[39m qa_chain = RetrievalQA.from_chain_type(\n\u001b[32m      5\u001b[39m     llm=llm,\n\u001b[32m      6\u001b[39m     chain_type=\u001b[33m\"\u001b[39m\u001b[33mstuff\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     retriever=\u001b[43mretriever\u001b[49m,\n\u001b[32m      8\u001b[39m     chain_type_kwargs={\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt_template},\n\u001b[32m      9\u001b[39m     return_source_documents=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "# 6ë‹¨ê³„: QA ì²´ì¸ ìƒì„±\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template},\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1177d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì‘ì„±\n",
    "test_questions = [\n",
    "    \"ì˜¨ë¼ì¸ ê²Œì„ì—ì„œ ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì•„ì´í…œì´ ì‚¬ë¼ì¡ŒëŠ”ë°, ê²Œì„íšŒì‚¬ê°€ ë³µêµ¬ë¥¼ ê±°ë¶€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‚˜ìš”?\",\n",
    "    \"ì¸í„°ë„· ê°•ì˜ë¥¼ ì¤‘ë„ í•´ì§€í•˜ë ¤ê³  í•˜ëŠ”ë° ê³¼ë„í•œ ìœ„ì•½ê¸ˆì„ ìš”êµ¬ë°›ê³  ìˆìŠµë‹ˆë‹¤. ì •ë‹¹í•œê°€ìš”?\",\n",
    "    \"ë¬´ë£Œì²´í—˜ í›„ ìë™ìœ¼ë¡œ ìœ ë£Œì „í™˜ë˜ì–´ ìš”ê¸ˆì´ ì²­êµ¬ë˜ì—ˆìŠµë‹ˆë‹¤. í™˜ë¶ˆ ê°€ëŠ¥í•œê°€ìš”?\",\n",
    "    \"ë¯¸ì„±ë…„ìê°€ ë¶€ëª¨ ë™ì˜ ì—†ì´ ê²Œì„ ì•„ì´í…œì„ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤. í™˜ë¶ˆë°›ì„ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?\",\n",
    "    \"ì˜¨ë¼ì¸ êµìœ¡ ì„œë¹„ìŠ¤ê°€ ê´‘ê³ ì™€ ë‹¤ë¥´ê²Œ ì œê³µë˜ì–´ ê³„ì•½ì„ í•´ì§€í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œê°€ìš”?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b0d5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8ë‹¨ê³„: ë¶„ìŸ ìœ í˜• ë¶„ë¥˜ í•¨ìˆ˜ (ì„ íƒ)\n",
    "def classify_dispute_type(query):\n",
    "    game_keywords = [\"ê²Œì„\", \"ì•„ì´í…œ\", \"ê³„ì •\", \"ìºë¦­í„°\", \"ë ˆë²¨\", \"ê¸¸ë“œ\", \"ì˜¨ë¼ì¸ê²Œì„\"]\n",
    "    elearning_keywords = [\"ê°•ì˜\", \"ì˜¨ë¼ì¸êµìœ¡\", \"ì´ëŸ¬ë‹\", \"ìˆ˜ê°•\", \"í™˜ë¶ˆ\", \"í™”ìƒêµìœ¡\"]\n",
    "    web_keywords = [\"ì›¹ì‚¬ì´íŠ¸\", \"ë¬´ë£Œì²´í—˜\", \"ìë™ê²°ì œ\", \"êµ¬ë…\", \"ì‚¬ì´íŠ¸\"]\n",
    "\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    if any(keyword in query_lower for keyword in game_keywords):\n",
    "        return \"ê²Œì„\"\n",
    "    elif any(keyword in query_lower for keyword in elearning_keywords):\n",
    "        return \"ì´ëŸ¬ë‹\"\n",
    "    elif any(keyword in query_lower for keyword in web_keywords):\n",
    "        return \"ì›¹ì½˜í…ì¸ \"\n",
    "    else:\n",
    "        return \"ê¸°íƒ€\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3cd1050",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qa_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mqa_chain\u001b[49m.run(\u001b[33m\"\u001b[39m\u001b[33mì˜¨ë¼ì¸ ê²Œì„ ì•„ì´í…œì´ ì‚¬ë¼ì¡ŒëŠ”ë° í™˜ë¶ˆë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[31mNameError\u001b[39m: name 'qa_chain' is not defined"
     ]
    }
   ],
   "source": [
    "response = qa_chain.run(\"ì˜¨ë¼ì¸ ê²Œì„ ì•„ì´í…œì´ ì‚¬ë¼ì¡ŒëŠ”ë° í™˜ë¶ˆë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba755e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-DD67osgJ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
