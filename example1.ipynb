{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed0e289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceee9c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hun\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edae620f-56b8-4e32-b020-6bcf68b782b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a281fc94-7a3a-4d94-8c1c-ff8f037fbc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000272FF4E2E90> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000272FF4E2AD0> root_client=<openai.OpenAI object at 0x00000272FF4E2990> root_async_client=<openai.AsyncOpenAI object at 0x00000272FF4E2710> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41fc58f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# chain 연결 (LCEL) prompt + llm + outputparser\u001b[39;00m\n\u001b[32m      4\u001b[39m output_parser = StrOutputParser()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m chain2 = \u001b[43mprompt\u001b[49m | llm | output_parser\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(chain2))\n",
      "\u001b[31mNameError\u001b[39m: name 'prompt' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL) prompt + llm + outputparser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f91284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n    You are an expert in AI Expert. Answer the question. \\n    <Question>: {input}에 대해 쉽게 반드시 한글로 설명해주세요.\")\\n    ')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}에 대해 쉽게 반드시 한글로 설명해주세요.\")\n",
    "    \"\"\")                                     \n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5c8e70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain 연결 (LCEL) prompt + llm 연결\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57e888e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL) prompt + llm + outputparser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5175503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**계란, 밥, 김치에 대한 설명**\n",
      "\n",
      "안녕하세요! 오늘은 한국의 전통적인 음식인 계란, 밥, 김치에 대해 알아보겠습니다.\n",
      "\n",
      "### 계란\n",
      "\n",
      "*   **계란**은 닭이 낳은 알을 말합니다.\n",
      "*   계란은 단백질, 비타민, 미네랄 등이 풍부하여 한국인의 주요 영양 공급원 중 하나입니다.\n",
      "*   계란은 다양한 방법으로 조리할 수 있습니다. 예를 들어, 계란을 삶아서 먹거나, 계란 프라이를 만들거나, 계란을 으깨서 스크램블을 만들 수 있습니다.\n",
      "\n",
      "### 밥\n",
      "\n",
      "*   **밥**은 쌀을 물에 삶아서 만든 음식입니다.\n",
      "*   밥은 한국인의 주식으로, 대부분의 식사에서 중심이 되는 음식입니다.\n",
      "*   밥은 소금, 참기름, 숟가락으로 떠서 다양한 반찬과 함께 먹습니다.\n",
      "\n",
      "### 김치\n",
      "\n",
      "*   **김치**는 한국 전통 음식 중 하나로, 채소(주로 배추)를 소금에 절이고, 고추장, 마늘, 생강, 젓갈 등의 양념을 넣어서 발효시킨 음식입니다.\n",
      "*   김치는 한국인의 밥상에서 빼놓을 수 없는 반찬 중 하나입니다. 김치는 발효식품으로, 유산균이 풍부하여 소화 건강에 좋습니다.\n",
      "*   김치는 다양한 종류가 있으며, 지역별로 특색 있는 김치를 즐길 수 있습니다.\n",
      "\n",
      "계란, 밥, 김치는 한국인의 전통적인 식사 구성 요소입니다. 이 음식들은 한국인의 영양 공급원으로서 중요한 역할을 하며, 한국 문화와도 깊은 관련이 있습니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"계란, 밥, 김치\"})\n",
    "    \n",
    "    # 스트리밍 출력\n",
    "    #print(answer)\n",
    "    for token in answer:\n",
    "        # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "        print(token, end=\"\", flush=True)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "452fe128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**김치볶음밥**\n",
      "\n",
      "*   **재료** 계란, 밥, 김치, 참기름, 고춧가루, 대파 \n",
      "*   **조리 방법**\n",
      "\n",
      "1.  김치를 잘게 썰고, 대파를 송송 썬다.\n",
      "2.  팬에 참기름을 두르고 다진 파를 넣고 볶다가 김치를 넣고 볶는다.\n",
      "3.  고춧가루를 뿌리고 볶다가 밥을 넣고 볶는다. \n",
      "4.  소금으로 간을 하고 마지막에 계란을 넣고 잘 섞어준다.\n"
     ]
    }
   ],
   "source": [
    "template_text = \"사용자가 재료를 입력하면 그 재료로 만들 수 있는 요리를 추천해주세요\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 계란, 밥, 김치\")\n",
    "              + \"\\n\\n 김치볶음밥으로 조리법도 알려줘\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a67f9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 한국 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추전한 영화의 제목을 먼저 알려주시고, 간단한 줄거리를 10문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8c565a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie I recommend is called '서울의 봄' or 'The Battle of Seoul'. \n",
      "\n",
      "Here is a brief summary of the movie in 10 sentences:\n",
      "\n",
      "'서울의 봄'은 2021년 7월에 개봉한 한국 영화입니다.\n",
      "이 영화는 한국 전쟁 이후 한반도에서 벌어진 9.17 군사 반란을 바탕으로 합니다.\n",
      "영화의 배경은 1980년대이며, 수도경비사령관과 그의 부하들이 반란군과 대결하는 이야기입니다.\n",
      "수도경비사령관과 그의 부하들은 반란군을 진압하기 위해 전투를 준비합니다.\n",
      "반란군은 수도경비사령부를 공격하고, 수도경비사령관과 그의 부하들은 반란군을 진압하기 위해 싸웁니다.\n",
      "영화는 액션 장르로, 전투 장면이 많습니다.\n",
      "수도경비사령관과 그의 부하들은 반란군을 상대로 많은 어려움을 겪지만, 결국에는 반란군을 진압합니다.\n",
      "영화는 대한민국의 역사적인 사건을 바탕으로 하며, 전투 장면이 واقع적으로 그려져 있습니다.\n",
      "이 영화는 한국 전쟁 이후의 대한민국의 상황을 잘 표현하고 있습니다.\n",
      "이 영화는 한국 영화 팬들에게 추천할 만한 영화입니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "try:\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1의 출력을 movie 입력 변수로 전달\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "    response = chain2.invoke({\"genre\": \"액션\"})\n",
    "    print(response)  \n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "410e6885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "키워드: 제미나이, 구글, AI\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 예시 데이터 3개 이상\n",
    "examples = [\n",
    "    {\n",
    "        \"news\": \"삼성전자가 내년 초에 자체적으로 개발한 인공지능(AI) 가속기를 처음으로 출시할 예정이다. 이는 AI 반도체 시장에서 지배적인 위치를 차지하고 있는 엔비디아의 독점을 도전하고, 세계 최고의 반도체 제조업체로서의 지위를 다시 확립하려는 삼성전자의 노력으로 해석된다.\",\n",
    "        \"keywords\": \"삼성전자, 인공지능, 엔비디아\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"세계보건기구(WHO)는 최근 새로운 건강 위기에 대응하기 위해 국제 협력의 중요성을 강조했다. 전염병 대응 역량의 강화와 글로벌 보건 시스템의 개선이 필요하다고 발표했다.\",\n",
    "        \"keywords\": \"세계보건기구, 건강위기, 국제협력\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"미국 연방준비제도(Fed)는 최근 기준금리를 동결하기로 결정했다. 이는 물가 상승률 둔화와 경기 침체 우려를 반영한 조치로 해석된다.\",\n",
    "        \"keywords\": \"연준, 기준금리, 경기침체\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예시 프롬프트\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{news}\"),\n",
    "    (\"ai\", \"키워드: {keywords}\")\n",
    "])\n",
    "\n",
    "# Few-shot 예시 템플릿 구성\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# 전체 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 뉴스 기사에서 핵심 키워드 3개를 뽑는 전문가입니다. 키워드는 쉼표로 구분해서 작성해주세요.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 모델 설정\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 구성\n",
    "chain = final_prompt | model\n",
    "\n",
    "# 테스트 실행\n",
    "test_news = {\n",
    "    \"input\": \"제미나이 2.0 플래시는 현재 구글 AI 스튜디오(Google AI Studio) 및 버텍스 AI(Vertex AI)에서 제미나이 API를 통해 개발자에게 실험 모델로 제공됩니다. 모든 개발자는 멀티모달 입력 및 텍스트 출력을 사용할 수 있으며, 텍스트 음성 변환(text-to-speech) 및 네이티브 이미지 생성은 일부 파트너들을 대상으로 제공됩니다. 내년 1월에는 더 많은 모델 사이즈와 함께 일반에 공개될 예정입니다.\"\n",
    "}\n",
    "\n",
    "result = chain.invoke(test_news)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd8de70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
